{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8213295,"sourceType":"datasetVersion","datasetId":4867780},{"sourceId":8447022,"sourceType":"datasetVersion","datasetId":5033379},{"sourceId":8467496,"sourceType":"datasetVersion","datasetId":5048484},{"sourceId":8516453,"sourceType":"datasetVersion","datasetId":5084606}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"color:#153BE4; font-size:50px; font-family:serif; background:#90BD59; padding-bottom:20px;padding-top:20px; border-radius: 15px;\n           font-weight:bold\" \n    align=\"center\"> \n    Neural Machine Translation using LSTM (Eng to Kan)\n</h1>\n\n<p style=\"font-size:18px\">\n    NMT is a very well known use case of NLP task, where the goal is to translate one languge to another language with the help of architectures known as encoder and decoder. Encoder takes the input language, generates an information rich representation which is then fed into the deocoder to generate the words of target language. This is a sequential task where encoder is trained in autoregressive manner and in the decoder we pass one token at a time to generate the next token. So in this sense the decoder acts a Generative model. The model architecture can be explained as below with a diagram.\n</p>\n<img src=\"https://i.postimg.cc/y8dvcFrH/Sequence-to-sequence-encoder-decoder-NMT-model.jpg\"  style=\"display: block; margin-left: auto; margin-right: auto;\"/>\n<br>\n<p style=\"font-size:18px\">\n    For our purpose we used LSTM for both encoder and decoder. Also in this task we used pretrained Glove Embeddings for the representation of english words and Indic Bert's embedding for the representation of Kannada language. \n</p>","metadata":{}},{"cell_type":"markdown","source":"## Load the libraries","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\nimport torch\nfrom tqdm import tqdm\nimport pandas as pd\nimport pickle\nimport re\nimport torch.nn.functional as F\nfrom transformers import AutoModel, AutoTokenizer\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nimport tensorflow as tf\nimport random\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom nltk.translate.bleu_score import SmoothingFunction\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-26T13:01:38.594335Z","iopub.execute_input":"2024-05-26T13:01:38.594586Z","iopub.status.idle":"2024-05-26T13:01:56.063770Z","shell.execute_reply.started":"2024-05-26T13:01:38.594563Z","shell.execute_reply":"2024-05-26T13:01:56.062936Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-26 13:01:47.922972: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 13:01:47.923065: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 13:01:48.068165: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the downloaded embeddings for Glove","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nglove_word_to_idx={}\nglove_vectors={}\ni=0\nwith open('/kaggle/input/glove6b100d-embedding/glove.6B.100d.txt') as fp:\n    for line in tqdm(fp.readlines()):\n        records = line.split()\n        word = records[0]\n        vector_dimensions = np.asarray(records[1:], dtype='float32')\n        glove_word_to_idx[word] = i\n        glove_vectors[i]=torch.tensor(vector_dimensions)\n        i+=1","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:02:17.172384Z","iopub.execute_input":"2024-05-26T13:02:17.173038Z","iopub.status.idle":"2024-05-26T13:02:38.539548Z","shell.execute_reply.started":"2024-05-26T13:02:17.173003Z","shell.execute_reply":"2024-05-26T13:02:38.538673Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"100%|██████████| 400000/400000 [00:16<00:00, 24341.58it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"## Dont run this cell \n\ntokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert',keep_accents=True,padding=True)\nmodel = AutoModel.from_pretrained('ai4bharat/indic-bert')\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Get the full vocabulary\nvocab = tokenizer.get_vocab()\n\nidx=0\nids_to_idx={}\nidx_to_ids={}\n\n# Filter the vocabulary to include only Kannada words\nkannada_words = {word: idx for word, idx in vocab.items() if any(0x0C80 <= ord(c) <= 0x0CFF for c in word)}\nspecial = ['<unk>','<pad>','▁']\nfor s in special:\n    tokens = tokenizer.encode(s, return_tensors=\"pt\")\n    ids = tokens\n    with torch.no_grad():\n        outputs = model(tokens)\n    embeddings = outputs.last_hidden_state[0]\n    for ids,emb in zip(tokens[0],embeddings):\n        ids=ids.item()\n        word = tokenizer.convert_ids_to_tokens(ids)\n        if ids not in ids_to_idx.keys():\n            ids_to_idx[ids] = {'word':word,'word_index':ids,'emb':emb}\n            idx_to_ids[ids] = {'word':word,'word_index':ids, 'emb':emb }\n    \nidx = 4\nfor words in tqdm(kannada_words.keys()):\n    if idx==8:\n        idx=9\n    tokens = torch.tensor([2,kannada_words[words],3]).unsqueeze(0)\n    with torch.no_grad():\n        outputs = model(tokens)\n    embeddings = outputs.last_hidden_state[0][1]\n    ids_to_idx[kannada_words[words]] = {'word':words,'word_index':idx, 'emb':embeddings}\n    idx_to_ids[idx] = {'word':words,'word_index': kannada_words[words], 'emb':embeddings}\n    idx+=1\n            \nimport pickle\n\n# Serialize the ids_to_idx dictionary\nwith open('kannada_word_embeddings_ids2idx.pkl', 'wb') as f:\n    pickle.dump(ids_to_idx, f)\n    \n\n# Serialize the ids_to_idx dictionary\nwith open('kannada_word_embeddings_idx2ids.pkl', 'wb') as f:\n    pickle.dump(idx_to_ids, f)","metadata":{"jupyter":{"source_hidden":true,"outputs_hidden":true},"execution":{"iopub.status.busy":"2024-05-26T08:41:09.036355Z","iopub.execute_input":"2024-05-26T08:41:09.036693Z"},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4a0ccd1f930455bb46c72a1c1e3fd88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9134c7eec87e4664b587fbb835abc212"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebc2e033f764d589e8419e7faf83e59"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n 52%|█████▏    | 11206/21383 [04:28<04:25, 38.40it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the data","metadata":{}},{"cell_type":"code","source":"Data_train = pd.read_csv('/kaggle/input/translation-dataset/team24_kn/team24_kn_train.csv',encoding='utf-8')\nData_valid =  pd.read_csv('/kaggle/input/translation-dataset/team24_kn/team24_kn_valid.csv',encoding='utf-8')\nData_test =  pd.read_csv('/kaggle/input/translation-dataset/team24_kn/team24_kn_test.csv',encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:02:38.551650Z","iopub.execute_input":"2024-05-26T13:02:38.551924Z","iopub.status.idle":"2024-05-26T13:02:39.059220Z","shell.execute_reply.started":"2024-05-26T13:02:38.551901Z","shell.execute_reply":"2024-05-26T13:02:39.058257Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load the kannada word embeddings\n\n<p style=\"font-size:18px\">\n    We have stored the embeddings in two pickle files, which contains a dictionary mapping of original index to word and to their embeddings and the other pickle file contains the inverse mapping from new index to original index and word embeddings. \n</p>","metadata":{}},{"cell_type":"code","source":"file_path = '/kaggle/input/d/anikbhowmickae20b102/kannada-embeddings/kannada_word_embeddings_ids2idx.pkl'\n\n# Open the pickle file for reading in binary mode\nwith open(file_path, 'rb') as f:\n    ids_to_idx = pickle.load(f)\n    \nfile_path = '/kaggle/input/d/anikbhowmickae20b102/kannada-embeddings/kannada_word_embeddings_idx2ids.pkl'\n\n# Open the pickle file for reading in binary mode\nwith open(file_path, 'rb') as f:\n    idx_to_ids = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids_to_idx[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:40:47.736788Z","iopub.execute_input":"2024-05-18T16:40:47.738199Z","iopub.status.idle":"2024-05-18T16:40:47.757877Z","shell.execute_reply.started":"2024-05-18T16:40:47.738151Z","shell.execute_reply":"2024-05-18T16:40:47.756135Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'word': '<pad>',\n 'word_index': 0,\n 'emb': tensor([ 1.8497e-01,  4.7676e-02,  1.7916e-02, -1.8901e-01, -2.1319e-02,\n         -4.3125e-02, -1.5480e-01,  2.7509e-02, -4.1240e-02,  1.9308e-01,\n         -2.2678e-01,  2.6876e-01,  7.7441e-02, -1.1246e-01, -1.3378e-01,\n          1.9812e-02,  6.3040e-03, -1.5274e-01,  7.5757e-03, -7.5364e-01,\n         -1.5213e-01, -2.0996e-01,  5.1003e-02, -8.9232e-02,  3.2150e-01,\n          4.5672e-01, -1.3179e-01, -7.0628e-02, -1.4835e-01, -5.5398e-02,\n          2.2579e-01,  2.9330e-01,  3.1553e-01, -2.3183e-01,  2.7504e-02,\n          9.0284e-02,  3.1039e-01, -2.3230e-02, -1.2556e-01,  7.2299e-03,\n         -5.5922e-01, -7.7349e-02, -2.1687e-01, -4.3368e-01, -1.9727e-02,\n          1.3920e-01, -2.7258e-01, -7.1891e-02,  7.5716e-03,  3.9337e-02,\n         -1.3009e-01, -2.7763e-01,  1.0540e-01,  2.8175e-01,  2.1879e-01,\n          3.0248e-01, -1.3106e-01,  1.3361e-01,  5.5977e-02,  2.3551e-02,\n          1.3561e-01, -4.0450e-01, -2.8044e-02,  1.5109e-01, -1.4453e+00,\n         -1.2516e-01,  1.1575e-01,  3.4172e-02,  5.3876e-01, -1.5242e-01,\n          1.8088e-01, -7.7522e-02,  2.0512e-01,  4.5701e-03,  1.4192e-01,\n         -2.5724e-01, -3.7430e-01,  7.1985e-02, -2.4377e-01, -1.4045e-03,\n         -8.7862e-02, -3.0596e-02, -3.8222e-01, -3.6328e-03,  8.4569e-02,\n          1.2280e-01, -1.9482e-01, -2.3827e-01, -1.7721e-02, -2.6235e-01,\n          7.8940e-02, -3.2466e-01,  7.7187e-01,  2.3240e-03, -2.6856e-01,\n          3.6100e-02, -1.5430e-01, -1.1666e-01,  1.1174e-01,  1.3391e-01,\n          5.0647e-02,  2.2708e-01,  1.1367e-01, -1.9450e-02,  8.3035e-04,\n          1.7990e-01, -1.3378e-01, -3.3782e-01, -2.2600e-02, -1.5767e-01,\n         -4.0900e-01,  2.3274e-01, -5.6602e-02,  9.1806e-02,  1.3555e-01,\n          1.1900e-02,  1.4941e-01,  7.2082e-01, -4.1174e-01,  6.1923e-01,\n          7.1338e-01,  3.6853e-01, -8.1689e-01, -2.5587e-01,  4.8598e-02,\n         -7.2812e-02,  8.9877e-02, -2.0656e-01,  1.7075e-01,  1.0588e-01,\n          1.9881e-01, -9.1294e-02,  4.6970e-01,  1.0866e-01, -1.0485e-01,\n         -1.9390e-01, -3.8064e-01, -1.9168e-01, -3.6444e-01,  3.3129e-02,\n         -2.2607e-01,  1.1704e-01, -1.4375e-01, -1.7551e-01, -4.3744e-01,\n          4.4394e-02,  1.0034e-01,  1.4268e-01,  1.3087e-01, -1.7907e-01,\n          2.8852e-01, -1.5280e-01,  2.8627e-01,  1.0678e-01, -2.4713e-01,\n         -1.5960e-01,  7.3326e-01,  4.5845e-01,  1.1371e-02, -1.0560e-01,\n          3.8269e-01, -1.2701e-01, -4.2928e-01, -2.3509e-02, -1.9354e-01,\n          2.3195e-01, -3.8078e-01, -7.2649e-01,  1.3384e-01, -1.7023e-01,\n          1.5120e-01,  1.1875e-02,  1.5757e-01, -6.0833e-02, -1.0900e-01,\n         -1.2950e-03,  2.0778e-02, -1.3033e-01,  3.1657e-01, -2.6914e-01,\n          4.0498e-02, -6.6027e-02, -9.5341e-02, -2.6993e-01,  9.5361e-02,\n         -1.1225e-02, -3.1006e-02, -2.9917e-02,  3.7098e-01, -2.6233e-01,\n         -1.0039e-01,  1.7642e-01,  1.1972e-02, -4.7090e-02, -4.8265e-01,\n          1.9979e-01, -5.7582e-02,  2.9027e-01, -6.7806e+00,  1.0533e-01,\n         -1.1178e-01,  7.7511e-01, -6.6959e-01,  2.8983e-02, -7.2951e-02,\n         -3.6146e-02, -1.8935e-01, -1.4837e-02,  3.9448e-01, -1.8420e-01,\n         -8.9849e-02, -2.9956e-01,  1.6038e-01, -2.5970e-01, -5.9938e-02,\n         -1.5881e-01,  3.0543e-02,  3.5006e-02, -2.7961e-01, -5.0703e-01,\n         -1.8446e-01,  2.7643e-01,  2.0538e-02, -2.7264e-01, -2.5305e-01,\n         -1.0277e-02,  1.9960e-01,  3.6242e-01, -7.0140e-02,  8.3084e-02,\n         -2.4657e-01,  1.1287e-01, -1.6008e-01,  8.9308e-02, -2.8367e-01,\n          3.2611e-01,  2.1515e-01, -1.3052e-01,  3.6703e-02,  4.2213e-02,\n          1.8771e-01,  2.1493e-01, -8.2921e-02,  4.9091e-02,  7.0835e-02,\n          4.1224e-01,  1.9289e-01,  9.6935e-02, -3.9631e-03, -2.9826e-01,\n         -3.2887e-01,  3.8118e-01, -2.2825e-01,  3.9540e-02,  6.6685e-02,\n          8.3227e-02,  5.9220e-02, -1.3231e-02,  2.5725e-01,  2.1000e-01,\n          6.8853e-02, -3.0231e-01,  1.4930e-01,  3.4097e-01,  2.8861e-02,\n         -3.3784e-01,  7.9349e-01, -6.9012e-02, -9.8982e-03,  2.8056e-01,\n          1.5946e-01, -2.7902e-02,  2.8219e-02, -2.8457e-01,  1.3275e-01,\n          6.9937e-01,  5.2466e-01,  2.5988e-01, -1.0757e-01,  1.9467e-01,\n         -7.2613e-02, -4.5461e-02,  1.1670e-01,  6.1316e-02, -3.1004e-02,\n          9.7727e-02,  7.7700e-02,  8.5609e-02, -1.0551e-01, -7.6602e-02,\n         -5.9044e-01, -2.5967e-01,  6.2222e-01, -3.9280e-02, -2.6790e-02,\n          1.8593e-01, -3.2582e-01, -2.7573e-02, -1.5807e-01, -4.4123e-01,\n         -1.8365e-01,  1.1956e-02,  1.1704e-01, -1.7409e-01, -6.4400e-02,\n          1.5188e-01, -2.7423e-01,  5.1484e-02, -6.4571e-02,  1.2688e-01,\n         -1.4900e-01,  3.2595e-02, -8.1281e-02,  1.2769e-01, -3.1509e-02,\n          1.1489e-01,  2.5473e-01,  1.6172e-01, -1.5621e-01,  1.4115e-01,\n         -4.4597e-01,  7.9239e-02, -1.8195e-01, -3.7292e-01,  2.6853e-01,\n          9.1734e-02, -4.8887e-01, -1.1584e-02, -1.0062e-01, -2.4777e-02,\n          1.0298e-01,  1.0517e-01,  6.9291e-02,  1.7612e-01,  6.7130e-02,\n          2.4874e-01, -4.6353e-02,  1.1971e-01, -1.9710e-01,  6.7788e-02,\n         -2.6016e-01, -1.6920e-01, -1.5415e-01, -3.8192e-02,  1.6852e-02,\n         -8.6645e-02, -8.9172e-02,  3.8645e-01,  1.5410e-01, -4.2279e-03,\n          6.9824e-02,  9.9415e-03, -1.3078e-01,  1.4410e-01, -1.1596e-01,\n         -2.8347e-01, -8.9370e-02, -1.0273e-01,  2.7179e-01,  7.9976e-03,\n          6.2193e-02, -3.7900e-02,  2.5712e-01,  7.6600e-03, -4.7396e-01,\n          2.4074e-01,  6.1698e-02, -1.1850e-01, -1.9520e-01, -5.0606e-02,\n          1.4678e-01,  1.0614e+00,  1.6745e-01,  1.7566e-01,  4.1162e-01,\n          1.3559e-01, -1.5102e-01, -3.8796e-02,  6.1935e-01, -3.7276e-02,\n         -1.3042e-02, -8.6553e-02,  3.9987e-01, -3.3702e-02,  2.0987e-02,\n          1.4645e-01,  4.3066e-01,  1.5188e-01, -2.0162e-01, -2.4621e-01,\n          3.3881e-01, -8.5240e-02, -1.1506e-01, -1.2858e-02,  8.4248e-02,\n         -1.7283e-01, -8.7047e-01,  4.8975e-02, -1.3653e-01, -1.3932e-01,\n         -6.5640e-02, -2.9549e-01, -1.7219e-01,  4.5240e-01, -2.6292e-01,\n          1.6680e-01,  2.4663e-01,  2.0317e-01, -2.1319e-01,  2.3263e-01,\n          4.2759e-02,  1.4364e-01, -2.2221e-01, -1.5947e-01,  4.6957e-02,\n          1.3663e-01,  2.7126e-01, -3.0554e-01,  2.8723e-02,  3.4812e-02,\n         -1.3511e-01, -2.0058e-01, -2.3266e-02, -3.5672e-01, -5.7678e-03,\n          9.9101e-03, -3.7542e-01, -8.3222e-02,  7.8454e-02,  4.0617e-02,\n         -2.6785e-01,  1.7118e-01, -3.4141e-01, -4.8009e-02, -2.4448e-02,\n         -1.4171e-01, -6.7332e-01, -4.4776e-02,  4.2299e-01, -2.8063e-01,\n          2.3724e-01, -1.8793e-02,  1.8431e-01, -2.6927e-01,  6.6784e-01,\n         -1.8234e-02, -5.5095e-02, -1.6805e-02,  6.0849e-03, -4.6655e-01,\n         -9.1971e-02, -1.6890e-01, -1.5104e-01,  4.7548e-02,  3.5436e-01,\n          3.8589e-01,  1.6184e-01,  1.4004e-01, -2.8822e-02, -6.5696e-02,\n         -5.7713e-01,  1.5196e-02, -1.2341e-01,  2.4189e-03, -1.9897e-02,\n          1.1471e-01,  2.1362e-02, -1.2524e-02, -4.4009e-02,  1.2399e-01,\n          1.3339e-01, -2.4028e-02,  7.3311e-02, -5.7473e-01,  1.3213e-02,\n         -1.2005e-01, -6.6399e-01, -5.3559e-01, -1.2133e-02,  1.0331e-03,\n          3.4367e-01, -3.6231e-02, -2.0893e-02, -3.7548e-02,  1.0161e-02,\n          7.2792e-02,  8.2384e-02,  1.5578e-01,  1.3116e-01, -7.0093e-04,\n         -9.7214e-02, -1.1630e-01, -4.0706e-01, -4.3802e-02, -5.0748e-02,\n         -1.8193e-01,  9.2952e-02,  1.2976e-01,  4.0279e-01, -2.6522e-01,\n          5.7851e-01, -9.1721e-03, -6.8857e-02, -1.1009e-01, -1.8420e-02,\n          2.2152e-01,  9.8567e-02, -6.9848e-02, -8.4083e-02, -3.1314e-01,\n         -1.2608e-01,  2.8400e-02,  4.5692e-01,  1.2554e-01, -1.6412e-01,\n         -9.9078e-01,  2.4175e-01, -3.6718e-03, -1.2775e-01,  2.1223e-01,\n          1.5269e-01, -7.5266e-02, -2.2649e-01,  5.3495e-01, -7.6598e-02,\n          5.2047e-03,  3.1718e-02, -8.5091e-02, -3.3446e-01,  7.5568e-04,\n          1.0134e-01,  5.7488e-02, -1.3482e-01, -2.9965e-02, -2.8864e-01,\n         -3.1203e-01,  6.7622e-02,  2.1600e-01, -1.0056e-01,  1.1157e-01,\n          1.6161e-01,  2.3799e-01,  1.3143e-01, -6.2994e-02,  6.7131e-02,\n          2.0102e-01, -2.7491e-01,  3.7839e-02, -4.0902e-02,  2.0253e-01,\n         -6.1761e-02,  3.9998e-02,  1.2014e-01, -1.8395e-01,  2.2052e-01,\n          2.2993e-01,  1.0174e-01, -3.4795e-01,  4.5108e-02, -2.7137e-01,\n         -1.9199e-01, -9.7266e-02,  2.0598e-01, -1.1025e-01,  3.0976e-02,\n         -2.8678e-01, -3.5463e-01, -1.7137e-02, -1.4498e-02, -2.3075e-02,\n         -3.1328e-01,  3.7291e-01,  6.9205e-03, -4.6835e-02, -5.1525e-01,\n         -6.5338e-02, -2.9171e-01, -2.4286e-01, -3.2549e-01,  3.1662e-01,\n          1.9874e-01, -7.7427e-01,  9.7642e-02, -2.4929e-01,  8.3407e-02,\n         -1.2142e-01, -1.2263e-01,  2.4992e-01,  2.0024e-01,  3.3143e-02,\n          1.0299e-01, -1.3864e-01,  1.7471e-01,  2.1799e-01, -2.3291e-01,\n          6.3521e-02, -2.8763e-01, -3.5073e-01, -3.3558e-01,  6.5782e-02,\n          2.8792e-01, -1.1849e-01,  1.2470e-01,  2.3398e-02, -2.4455e-01,\n         -2.1957e-01, -2.3117e-02,  3.9592e-01,  1.8268e-01,  7.2849e-02,\n         -7.4503e-02, -1.6195e-01, -3.1450e-01, -1.4215e-01, -1.1792e-01,\n          2.1365e-01,  1.1325e+00, -3.8934e-01, -3.6200e-01,  2.0902e-01,\n          3.9753e-02, -1.3891e-01,  2.5801e-01,  7.3271e-02, -1.7088e-01,\n         -1.0062e-01,  8.8901e-02,  1.9695e-01,  3.0335e-01, -1.9615e-01,\n         -2.1531e-01, -2.4721e-02, -1.5423e-01, -6.7582e-02, -3.8111e-01,\n         -2.3489e-01,  1.1301e-01, -2.4690e-01, -1.9352e-01, -1.8066e-01,\n         -1.0061e-01,  6.5584e-02,  8.1274e-02, -2.5490e-01, -2.3749e-01,\n         -1.8318e-01, -1.2346e-01,  1.3539e-02, -5.1840e-02, -2.2344e-01,\n         -5.1114e-02, -4.1958e-02,  1.2169e-01,  1.7125e-01, -8.1047e-02,\n          1.7272e-01,  5.3141e-01,  6.8726e-02,  1.6323e-01, -1.6429e-03,\n         -1.1166e-01,  1.6838e-01,  1.6353e-01,  2.4560e-03, -1.3307e-01,\n          2.0334e-01, -7.1145e-02, -1.6250e-01, -1.5076e-02, -1.4190e-01,\n         -2.4536e-02,  2.1099e-01, -1.7637e-01, -6.3272e-02, -4.8995e-03,\n          1.5679e-01, -9.9525e-02, -6.4033e-02,  3.3731e-01, -1.7885e-01,\n          2.6810e-01,  5.1490e-02, -1.5401e-01,  3.6712e-01, -6.4217e-02,\n         -1.2374e-01,  1.7868e-01, -9.0834e-02,  2.0142e-01, -1.2588e-01,\n         -2.7338e-01,  2.6768e-01, -2.8389e-02, -1.7199e-01, -8.1873e-02,\n          2.8865e-01, -3.9625e-02,  1.2274e-01, -2.2016e-01, -1.2575e-01,\n         -3.7352e-01, -2.8967e-01, -1.9428e-01, -2.7676e-01, -1.6746e-01,\n         -9.6043e-02, -1.4967e-01,  3.6260e-03,  7.2442e-02, -6.8442e-02,\n         -2.8263e-01,  1.8749e-01,  9.8932e-02,  4.6062e-02,  8.7898e-02,\n         -1.4333e-02, -1.6637e-03,  1.3584e-01, -3.6324e-02,  4.1856e-01,\n         -9.3582e-03, -5.2915e-04,  1.1126e-01,  5.6699e-02, -3.6641e-01,\n          7.4076e-02,  3.7768e-01, -3.8427e-02,  7.8115e-02, -5.5301e-02,\n          7.5112e-02, -1.4841e-01,  8.3377e-02, -3.0695e-01, -2.9446e-01,\n         -2.2840e-01,  9.6153e-02, -7.9946e-02, -2.7352e-02, -3.1221e-01,\n          1.4539e-01,  1.4994e-01,  3.1790e-01,  2.9883e-01,  3.5982e-02,\n         -2.8717e-02,  4.3734e-02,  1.1863e-01, -3.0056e-01, -3.9329e-02,\n          1.6859e-01, -2.0770e-01, -1.0118e-01,  1.8450e-01,  9.0377e-02,\n          3.5348e-01,  1.9856e-01, -6.9655e-02,  2.8653e-01, -1.4498e-01,\n          5.9474e-02,  1.2191e-01, -1.2336e-01,  5.8506e-01,  8.1137e-02,\n         -2.8298e-01,  8.7839e-02, -4.0826e-01])}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load the auto tokenizer for Indic-Bert\n\n<p style=\"font-size:18px\">\n    Perform preprocessing for the kannada sentences. \n</p>","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert',keep_accents=True,padding=True)\n\n\ndef preprocess_text(text):\n    # Remove special characters, English numbers, full stops, and emojis\n    cleaned_text = re.sub(r'[^\\u0C80-\\u0CFF\\s]', '', text)  # Keep Kannada characters and whitespace\n    cleaned_text = re.sub(r'\\d+', '', cleaned_text)  # Remove English numbers\n    cleaned_text = re.sub(r'\\.', '', cleaned_text)  # Remove full stops\n    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Remove extra whitespace\n    return cleaned_text.strip()  # Remove leading and trailing whitespace\n\n\n\ndef get_tokens(sentences):\n    # Tokenize each sentence and convert tokens to integers\n    tokenized_sentences = [tokenizer.encode(sent, return_tensors='pt')[0] for sent in sentences]\n    # Convert tokens to integers and collect them in a list\n    tokenized_sentences_int_org = [[int(token) for token in tokens] for tokens in tokenized_sentences]\n    # Find the maximum sequence length\n    tokenized_sentences_int_mod = [[ids_to_idx[i]['word_index'] for i in tokens] for tokens in tokenized_sentences_int_org]\n    max_length = max(len(tokens) for tokens in tokenized_sentences)\n    return max_length, tokenized_sentences_int_mod\n\ndef pad_sequences(sentences,max_length):\n    padded_seq = [sent + [0] * (max_length - len(sent)) for sent in sentences]\n    return padded_seq\n\ndef embeddings_target_org(Y):\n    all_sequences_embeddings = []\n    for sequence in Y:\n        embeddings_list = [idx_to_ids[i.item()]['emb'] for i in sequence]\n        # Stack the list of embeddings into a single tensor for the current sequence\n        sequence_embeddings_tensor = torch.stack(embeddings_list)\n        # Append the stacked tensor to the list of all sequences' embeddings\n        all_sequences_embeddings.append(sequence_embeddings_tensor)\n    all_sequences_tensor = torch.stack(all_sequences_embeddings)\n    \n    return all_sequences_tensor","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:02:46.632690Z","iopub.execute_input":"2024-05-26T13:02:46.633084Z","iopub.status.idle":"2024-05-26T13:02:50.662928Z","shell.execute_reply.started":"2024-05-26T13:02:46.633040Z","shell.execute_reply":"2024-05-26T13:02:50.662139Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07f57e8ba6864967a6c09d1fc26d3688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74c24de4343a4938b7b2a54bdae4d505"}},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"font-size:18px\">\n    Preprocess the english sentences. \n</p>","metadata":{}},{"cell_type":"code","source":"def preprocess_source(text):\n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Remove special characters and numbers\n    text = re.sub(r'[^a-z\\s]', '', text)\n    \n    return text\n\ndef get_tokens_source(sentences):\n    tokenized_sent = [[glove_word_to_idx[word] for word in sent.split() if word in glove_word_to_idx] for sent in sentences]\n    return tokenized_sent\n\ndef pad_source(y):\n    max_len = 0\n    for i,sent in enumerate(y):\n        if max_len<len(sent):\n            max_len = len(sent)\n            idx = i\n    \n    padded_seq = [sent+[2]*(max_len-len(sent)) for sent in y]\n    return padded_seq\n\ndef embeddings_source(text):\n    all_sequences_embeddings = []\n    for sent in text:\n        embeddings_list = [glove_vectors[i.item()] for i in sent]\n        sequence_embeddings_tensor = torch.stack(embeddings_list)\n        # Append the stacked tensor to the list of all sequences' embeddings\n        all_sequences_embeddings.append(sequence_embeddings_tensor)\n    all_sequences_tensor = torch.stack(all_sequences_embeddings)\n    \n    return all_sequences_tensor","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:02:50.671045Z","iopub.execute_input":"2024-05-26T13:02:50.671316Z","iopub.status.idle":"2024-05-26T13:02:50.679621Z","shell.execute_reply.started":"2024-05-26T13:02:50.671295Z","shell.execute_reply":"2024-05-26T13:02:50.678639Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X,dtype=torch.int32)\n        self.y = torch.tensor(y,dtype=torch.int32)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:02:50.680957Z","iopub.execute_input":"2024-05-26T13:02:50.681679Z","iopub.status.idle":"2024-05-26T13:02:50.698830Z","shell.execute_reply.started":"2024-05-26T13:02:50.681646Z","shell.execute_reply":"2024-05-26T13:02:50.698084Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## preprocess and pad the sentences","metadata":{}},{"cell_type":"code","source":"Data_train['target']=Data_train['target'].apply(preprocess_text)\nData_valid['target']=Data_valid['target'].apply(preprocess_text)\nData_test['target']=Data_test['target'].apply(preprocess_text)\n\nmax_len, Y_train = get_tokens(Data_train['target'].values)\nY_train = pad_sequences(Y_train,max_len)\n\nmax_len, Y_valid = get_tokens(Data_valid['target'].values)\nY_valid = pad_sequences(Y_valid,max_len)\n\nmax_len, Y_test = get_tokens(Data_test['target'].values)\nY_test = pad_sequences(Y_test,max_len)\n\nData_train['source'] = Data_train['source'].apply(preprocess_source)\nData_valid['source'] = Data_valid['source'].apply(preprocess_source)\nData_test['source'] = Data_test['source'].apply(preprocess_source)\n\nX_train = get_tokens_source(Data_train['source'].values)\nX_train = pad_source(X_train)\n\nX_valid = get_tokens_source(Data_valid['source'].values)\nX_valid = pad_source(X_valid)\n\nX_test = get_tokens_source(Data_test['source'].values)\nX_test = pad_source(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:02:50.700031Z","iopub.execute_input":"2024-05-26T13:02:50.700297Z","iopub.status.idle":"2024-05-26T13:03:19.275905Z","shell.execute_reply.started":"2024-05-26T13:02:50.700275Z","shell.execute_reply":"2024-05-26T13:03:19.274833Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"Data_train['source'][0]","metadata":{"execution":{"iopub.status.busy":"2024-05-20T14:03:28.332018Z","iopub.execute_input":"2024-05-20T14:03:28.332319Z","iopub.status.idle":"2024-05-20T14:03:28.338252Z","shell.execute_reply.started":"2024-05-20T14:03:28.332294Z","shell.execute_reply":"2024-05-20T14:03:28.337339Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"'the role of parents'"},"metadata":{}}]},{"cell_type":"code","source":"X_train[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-20T14:03:41.520057Z","iopub.execute_input":"2024-05-20T14:03:41.520718Z","iopub.status.idle":"2024-05-20T14:03:41.528034Z","shell.execute_reply.started":"2024-05-20T14:03:41.520684Z","shell.execute_reply":"2024-05-20T14:03:41.527002Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"[0,\n 542,\n 3,\n 1108,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2,\n 2]"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train, Y_train)\nvalid_dataset = CustomDataset(X_valid, Y_valid)\ntest_dataset = CustomDataset(X_test, Y_test)\n# Create a DataLoader\nTrain_data = DataLoader(train_dataset, batch_size=128, shuffle=False)\nVal_data = DataLoader(valid_dataset, batch_size=128, shuffle=False)\nTest_data = DataLoader(test_dataset, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:03:19.277232Z","iopub.execute_input":"2024-05-26T13:03:19.277520Z","iopub.status.idle":"2024-05-26T13:03:23.432249Z","shell.execute_reply.started":"2024-05-26T13:03:19.277496Z","shell.execute_reply":"2024-05-26T13:03:23.431307Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"num_vocabs_kannada = len(ids_to_idx)# about 21K words+subwords","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:03:23.433429Z","iopub.execute_input":"2024-05-26T13:03:23.434473Z","iopub.status.idle":"2024-05-26T13:03:23.438320Z","shell.execute_reply.started":"2024-05-26T13:03:23.434445Z","shell.execute_reply":"2024-05-26T13:03:23.437371Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Model architecture\n<p style=\"font-size:18px\">\n    The model's decoder will be trained in teacher forcing fashion, meaning sometimes it uses predicted token to predict the next token or actula token to predict the next token, this way training makes the model more robust during infernce as during inference we only use the previous predicted token to predict the next token. \n</p>","metadata":{}},{"cell_type":"code","source":"class Encoder(torch.nn.Module):\n    def __init__(self, embedding_dim=100, hidden_size=256):\n        super(Encoder, self).__init__()\n        self.embedding = embeddings_source\n        self.lstm = torch.nn.LSTM(embedding_dim, hidden_size, num_layers = 1, bidirectional=False, dropout=0.2)\n        \n    def forward(self, inputs):\n        embedded = self.embedding(inputs).to(inputs.device)\n        outputs, (hidden, cell) = self.lstm(embedded)\n        \n        return outputs, hidden, cell\n    \nclass Decoder(torch.nn.Module):\n    def __init__(self, embedding_dim=768, hidden_size=256):\n        super(Decoder, self).__init__()\n        self.embedding = embeddings_target_org\n        self.lstm = torch.nn.LSTM(embedding_dim, hidden_size, num_layers = 1, bidirectional=False, dropout=0.2)\n        self.linear = torch.nn.Linear(hidden_size,num_vocabs_kannada)\n        \n    def forward(self,inputs,hidden_state=None, cell_state=None):\n        inputs = inputs.unsqueeze(0)\n        embedded = self.embedding(inputs).to(inputs.device)\n    \n        outputs, (hidden, cell) = self.lstm(embedded, (hidden_state,cell_state))\n        \n        outputs = self.linear(outputs)\n        \n        return outputs.squeeze(0), hidden, cell\n    \n    \nclass Seq2Seq(torch.nn.Module):\n    def __init__(self):\n        super(Seq2Seq,self).__init__()\n        self.encoder_model = Encoder()\n        self.decoder_model = Decoder()\n    \n    \n    def forward(self,inputs,target=None):\n        teacher_forcing_ratio = 0.5\n        encoder_outputs, encoder_hidden , encoder_cell = self.encoder_model(inputs)\n\n        # Initialize decoder hidden state with encoder final hidden state\n        decoder_hidden = encoder_hidden\n        \n        decoder_cell = encoder_cell\n        batch_size = inputs.size(1)\n        \n        # Initialize decoder input with SOS token\n        \n        decoder_input = (target[0] if target is not None else torch.tensor([2] * batch_size, device=inputs.device))\n        \n        #print(decoder_input)\n        # Forward pass through decoder one time step at a time\n        output_seq_len = 172\n        \n        outputs = torch.zeros(output_seq_len, batch_size, num_vocabs_kannada).to(inputs.device)\n        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n        if target!=None:\n            for t in range(1, output_seq_len):\n                decoder_output, decoder_hidden, decoder_cell = self.decoder_model(decoder_input, decoder_hidden, decoder_cell)\n                outputs[t] = decoder_output \n                #print(\"out_shape\",outputs[t].shape)\n                #print(\"target_shape\",target[t].shape)\n                decoder_input = (target[t] if use_teacher_forcing else outputs[t].argmax(1))\n        \n        \n        \n        elif target==None:\n            output_seq_len = 172\n            outputs = torch.zeros(output_seq_len, batch_size, num_vocabs_kannada).to(inputs.device)\n            for t in range(1, output_seq_len):\n                decoder_output, decoder_hidden, decoder_cell = self.decoder_model(decoder_input, decoder_hidden, decoder_cell)\n                outputs[t] = decoder_output \n                decoder_input = outputs[t].argmax(1)\n                    \n        return outputs\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:05:23.051672Z","iopub.execute_input":"2024-05-26T13:05:23.052346Z","iopub.status.idle":"2024-05-26T13:05:23.070501Z","shell.execute_reply.started":"2024-05-26T13:05:23.052311Z","shell.execute_reply":"2024-05-26T13:05:23.069580Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"Data_train['target'][0]# one sample","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:09:05.127521Z","iopub.execute_input":"2024-05-18T18:09:05.128356Z","iopub.status.idle":"2024-05-18T18:09:05.134964Z","shell.execute_reply.started":"2024-05-18T18:09:05.128320Z","shell.execute_reply":"2024-05-18T18:09:05.133922Z"},"trusted":true},"execution_count":205,"outputs":[{"execution_count":205,"output_type":"execute_result","data":{"text/plain":"'ಆಗಿನ ಪೋಷಕರ ಪಾತ್ರವೂ'"},"metadata":{}}]},{"cell_type":"code","source":"''.join([idx_to_ids[id.item()]['word'] for id in y[0] if id not in [1,0,2,3,8]])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T18:08:40.948416Z","iopub.execute_input":"2024-05-18T18:08:40.948870Z","iopub.status.idle":"2024-05-18T18:08:40.968127Z","shell.execute_reply.started":"2024-05-18T18:08:40.948831Z","shell.execute_reply":"2024-05-18T18:08:40.966737Z"},"trusted":true},"execution_count":203,"outputs":[{"execution_count":203,"output_type":"execute_result","data":{"text/plain":"'▁ಆಗಿನ▁ಪೋಷಕರ▁ಪಾತ್ರವೂ'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Bleu score metrics","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:18px\">\n    For determining the efficiency of the model we are Bleu-1, Bleu-2, Bleu-3 and Bleu-4. \n</p>","metadata":{}},{"cell_type":"code","source":"chencherry = SmoothingFunction()\ndef id_to_word(texts):\n    to_remove = [1,0,2,3,8]\n    cleaned_texts = []\n    for text in texts:\n        final = [idx_to_ids[id.item()]['word'] for id in text if id not in to_remove]\n        cleaned_texts.append(final)\n    return cleaned_texts\n\ndef calculate_bleu(y_true, y_pred,wt):\n    y_true = id_to_word(y_true)\n    y_pred = id_to_word(y_pred)\n    #print(y_true)\n    #print(y_pred)\n    bleu_scores = torch.tensor([sentence_bleu([s1],s2,weights = wt,smoothing_function=chencherry.method1)  for s1,s2 in zip(y_true,y_pred)],dtype=torch.float32)\n    #print(bleu_scores)\n    return torch.mean(bleu_scores)\n\ndef bleu_1_score(y_true,y_pred):\n    return calculate_bleu(y_true, y_pred,[1,0,0,0])\n\ndef bleu_2_score(y_true,y_pred):\n    return calculate_bleu(y_true, y_pred,[1/2,1/2,0,0])\n\ndef bleu_3_score(y_true,y_pred):\n    return calculate_bleu(y_true, y_pred,[1/3,1/3,1/3,0])\n\ndef bleu_4_score(y_true,y_pred):\n    return calculate_bleu(y_true, y_pred,[1/4,1/4,1/4,1/4])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:05:26.111409Z","iopub.execute_input":"2024-05-26T13:05:26.112139Z","iopub.status.idle":"2024-05-26T13:05:26.121663Z","shell.execute_reply.started":"2024-05-26T13:05:26.112108Z","shell.execute_reply":"2024-05-26T13:05:26.120691Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class CSVLogger:\n    def __init__(self, filename, fieldnames):\n        self.filename = filename\n        self.fieldnames = fieldnames\n        self.is_first_row = not os.path.exists(filename)\n        self.df = pd.DataFrame(columns=self.fieldnames)\n        self.df.to_csv(self.filename, index=False)\n\n    def log(self, values):\n        self.df.loc[len(self.df)]=values\n        self.df.to_csv(self.filename,index=False)\n        self.is_first_row = False\n\n    def close(self):\n        pass  # Nothing to do for closing a Pandas-based logger\n\nnames = ['epoch', 'loss', 'bleu_1', 'bleu_2', 'bleu_3', 'bleu_4',\n         'val_loss', 'val_bleu_1', 'val_bleu_2', 'val_bleu_3', 'val_bleu_4']\n\nCSV_logger = CSVLogger('training_logs.csv', fieldnames=names)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:05:29.577732Z","iopub.execute_input":"2024-05-26T13:05:29.578075Z","iopub.status.idle":"2024-05-26T13:05:29.588085Z","shell.execute_reply.started":"2024-05-26T13:05:29.578050Z","shell.execute_reply":"2024-05-26T13:05:29.586956Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{}},{"cell_type":"code","source":"def train_loop(model, criterion, optimizer, device, Trainloader,Val_loader, Epochs=10):    \n    model = model.to(device)\n    prev_best_loss = float('inf') \n    for epoch in range(Epochs):  # loop over the dataset multiple times\n        print(f\"Epoch {epoch+1}\")\n        # Training phase\n        model.train()  # Set the model to training mode\n        train_loss = 0.0\n        val_loss = 0.0\n        bleu_1 = 0.0\n        bleu_2 = 0.0\n        bleu_3 = 0.0\n        bleu_4 = 0.0\n        \n        bleu_1_val = 0.0\n        bleu_2_val = 0.0\n        bleu_3_val = 0.0\n        bleu_4_val = 0.0\n        \n        progress_bar = tf.keras.utils.Progbar(len(Trainloader))\n        for i, data in enumerate(Trainloader):\n            inputs, targets = data\n            # transpose the samples so the batch comes on last dimension\n            inputs = inputs.T.to(device)\n            targets = targets.T.to(device)\n            #print(targets.shape)\n            optimizer.zero_grad()\n            outputs = model(inputs,targets)\n            outputs_flattened = outputs[1:].reshape(-1, outputs.shape[-1])\n            targets_flattened = targets[1:].reshape(-1)\n            loss = criterion(outputs_flattened, targets_flattened.to(torch.long))\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm = 1)\n            optimizer.step()\n            \n            Y_pred= torch.argmax(outputs,axis=-1).T.detach()\n            Y_true=targets.T.detach()\n            \n            train_loss=train_loss*i\n            train_loss += loss.item()\n            train_loss/=(i+1)\n            \n            bleu_1=bleu_1*i\n            bleu_1+=bleu_1_score(Y_true,Y_pred)\n            bleu_1/=(i+1)\n\n            bleu_2=bleu_2*i\n            bleu_2+=bleu_2_score(Y_true,Y_pred)\n            bleu_2/=(i+1)\n            \n            bleu_3=bleu_3*i\n            bleu_3+=bleu_3_score(Y_true,Y_pred)\n            bleu_3/=(i+1)\n            \n            bleu_4=bleu_4*i\n            bleu_4+=bleu_4_score(Y_true,Y_pred)\n            bleu_4/=(i+1)\n            \n        \n                \n            # Update progress bar\n            progress_bar.update(i + 1, [('train_loss', train_loss),('bleu_1', bleu_1),('bleu_2', bleu_2),\n                                        ('bleu_3', bleu_3),('bleu_4', bleu_4)])\n            \n            del inputs\n            del targets\n            del outputs\n            torch.cuda.empty_cache()\n\n\n        # Validation phase\n        model.eval()  # Set the model to evaluation mode\n        \n        with torch.no_grad():\n            progress_bar = tf.keras.utils.Progbar(len(Val_loader))\n            for i, data in enumerate(Val_loader):\n                inputs, targets = data\n                inputs, targets = inputs.T.to(device), targets.T.to(device)\n                outputs = model(inputs)\n                outputs_flattened = outputs.reshape(-1, outputs.shape[-1])\n                targets_flattened = targets.reshape(-1)\n                loss = criterion(outputs_flattened, targets_flattened.to(torch.long))\n                \n                Y_pred= torch.argmax(outputs,axis=-1).T.detach()\n                Y_true=targets.T.detach()\n                \n                val_loss=val_loss*i\n                val_loss += loss.item()\n                val_loss/=(i+1)\n                \n                bleu_1_val=bleu_1_val*i\n                bleu_1_val+=bleu_1_score(Y_true,Y_pred)\n                bleu_1_val/=(i+1)\n\n                bleu_2_val=bleu_2_val*i\n                bleu_2_val+=bleu_2_score(Y_true,Y_pred)\n                bleu_2_val/=(i+1)\n            \n                bleu_3_val=bleu_3_val*i\n                bleu_3_val+=bleu_3_score(Y_true,Y_pred)\n                bleu_3_val/=(i+1)\n            \n                bleu_4_val=bleu_4_val*i\n                bleu_4_val+=bleu_4_score(Y_true,Y_pred)\n                bleu_4_val/=(i+1)\n                \n                progress_bar.update(i + 1, [('val_loss', val_loss),('val_bleu_1', bleu_1_val),('val_bleu_2', bleu_2_val),\n                                        ('val_bleu_3', bleu_3_val),('val_bleu_4', bleu_4_val)])\n                \n                del inputs\n                del targets\n                del outputs\n                torch.cuda.empty_cache()\n                \n                \n        logs={'epoch':epoch,'loss':train_loss, 'bleu_1':bleu_1,'bleu_2':bleu_2,'bleu_3':bleu_3,'bleu_4':bleu_4,\n           'val_loss':val_loss, 'val_bleu_1':bleu_1_val, 'val_bleu_2':bleu_2_val, 'val_bleu_3':bleu_3_val, 'val_bleu_4':bleu_4_val}\n        CSV_logger.log(logs)\n\n\n        # Print statistics\n        print(f\"Val Loss: {val_loss:.4f}, val_bleu_1: {bleu_1_val:.4f}, val_bleu_2: {bleu_2_val:.4f}, val_bleu_3: {bleu_3_val:.4f}, val_bleu_4: {bleu_4_val:.4f},\")\n        \n        \n        \n        # Save model if validation loss improves\n        if val_loss < prev_best_loss:\n            print(f\"Validation loss improved from {prev_best_loss:.4f}. Saving model...\")\n            torch.save(model.state_dict(), f\"LSTM_model_epoch_{epoch+1}_val_loss_{val_loss:.4f}.pth\")\n            prev_best_loss = val_loss\n        else:\n            print(f\"Validation loss did not improve from {prev_best_loss:.4f}\")\n\n    print(\"Finished Training\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:05:31.136783Z","iopub.execute_input":"2024-05-26T13:05:31.137389Z","iopub.status.idle":"2024-05-26T13:05:31.160653Z","shell.execute_reply.started":"2024-05-26T13:05:31.137356Z","shell.execute_reply":"2024-05-26T13:05:31.159669Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:05:32.724529Z","iopub.execute_input":"2024-05-26T13:05:32.724914Z","iopub.status.idle":"2024-05-26T13:05:32.731093Z","shell.execute_reply.started":"2024-05-26T13:05:32.724884Z","shell.execute_reply":"2024-05-26T13:05:32.730152Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"model = Seq2Seq()\nmodel.load_state_dict(torch.load(\"/kaggle/input/translation-model-english-kan/LSTM_model_epoch_11_val_loss_0.5548.pth\"))\n#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:05:37.572532Z","iopub.execute_input":"2024-05-26T13:05:37.573407Z","iopub.status.idle":"2024-05-26T13:05:37.657356Z","shell.execute_reply.started":"2024-05-26T13:05:37.573373Z","shell.execute_reply":"2024-05-26T13:05:37.656527Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train the model\n<p style=\"font-size:18px\">\n    Please note the model is trained for nearly 50 epochs and each epoch took almost 3 hours, so we couldnot continue with the training for longer epochs to generate better result, the model was checkpointed and reloaded and trained several times. \n</p>","metadata":{}},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrained_model = train_loop(model, criterion, optimizer, device, Train_data,Val_data, Epochs=6)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:49:58.014518Z","iopub.execute_input":"2024-05-25T18:49:58.014870Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7520s\u001b[0m 14s/step - train_loss: 0.4375 - bleu_1: 0.0592 - bleu_2: 0.0244 - bleu_3: 0.0167 - bleu_4: 0.0143\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2035s\u001b[0m 13s/step - val_loss: 0.5520 - val_bleu_1: 0.0440 - val_bleu_2: 0.0194 - val_bleu_3: 0.0141 - val_bleu_4: 0.0125\nVal Loss: 0.5537, val_bleu_1: 0.0443, val_bleu_2: 0.0196, val_bleu_3: 0.0142, val_bleu_4: 0.0125,\nValidation loss improved from inf. Saving model...\nEpoch 2\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7530s\u001b[0m 14s/step - train_loss: 0.4296 - bleu_1: 0.0628 - bleu_2: 0.0257 - bleu_3: 0.0175 - bleu_4: 0.0150\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2043s\u001b[0m 13s/step - val_loss: 0.5518 - val_bleu_1: 0.0460 - val_bleu_2: 0.0203 - val_bleu_3: 0.0147 - val_bleu_4: 0.0129\nVal Loss: 0.5535, val_bleu_1: 0.0457, val_bleu_2: 0.0203, val_bleu_3: 0.0146, val_bleu_4: 0.0128,\nValidation loss improved from 0.5537. Saving model...\nEpoch 3\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7502s\u001b[0m 14s/step - train_loss: 0.4180 - bleu_1: 0.0698 - bleu_2: 0.0288 - bleu_3: 0.0193 - bleu_4: 0.0164\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2038s\u001b[0m 13s/step - val_loss: 0.5512 - val_bleu_1: 0.0448 - val_bleu_2: 0.0202 - val_bleu_3: 0.0146 - val_bleu_4: 0.0128\nVal Loss: 0.5528, val_bleu_1: 0.0445, val_bleu_2: 0.0200, val_bleu_3: 0.0144, val_bleu_4: 0.0126,\nValidation loss improved from 0.5535. Saving model...\nEpoch 4\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7606s\u001b[0m 14s/step - train_loss: 0.4121 - bleu_1: 0.0742 - bleu_2: 0.0309 - bleu_3: 0.0206 - bleu_4: 0.0174\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2115s\u001b[0m 13s/step - val_loss: 0.5529 - val_bleu_1: 0.0499 - val_bleu_2: 0.0223 - val_bleu_3: 0.0161 - val_bleu_4: 0.0141\nVal Loss: 0.5542, val_bleu_1: 0.0498, val_bleu_2: 0.0222, val_bleu_3: 0.0160, val_bleu_4: 0.0140,\nValidation loss did not improve from 0.5528\nEpoch 5\n\u001b[1m334/547\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m49:34\u001b[0m 14s/step - train_loss: 0.4091 - bleu_1: 0.0768 - bleu_2: 0.0320 - bleu_3: 0.0213 - bleu_4: 0.0181","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(model, criterion, device, data_loader): \n    model.eval()\n    with torch.no_grad():\n        val_loss = 0.0\n        bleu_1_val = 0.0\n        bleu_2_val = 0.0\n        bleu_3_val = 0.0\n        bleu_4_val = 0.0\n        progress_bar = tf.keras.utils.Progbar(len(data_loader))\n        for i, data in enumerate(data_loader):\n            inputs, targets = data\n            inputs, targets = inputs.T.to(device), targets.T.to(device)\n            outputs = model(inputs)\n            outputs_flattened = outputs.reshape(-1, outputs.shape[-1])\n            #print(outputs_flattened.shape)\n            targets_flattened = targets.reshape(-1)\n            #print(targets.shape)\n            loss = criterion(outputs_flattened, targets_flattened.to(torch.long))\n                \n            Y_pred= torch.argmax(outputs,axis=-1).T.detach()\n            Y_true=targets.T.detach()\n                \n            val_loss=val_loss*i\n            val_loss += loss.item()\n            val_loss/=(i+1)\n                \n            bleu_1_val=bleu_1_val*i\n            bleu_1_val+=bleu_1_score(Y_true,Y_pred)\n            bleu_1_val/=(i+1)\n\n            bleu_2_val=bleu_2_val*i\n            bleu_2_val+=bleu_2_score(Y_true,Y_pred)\n            bleu_2_val/=(i+1)\n            \n            bleu_3_val=bleu_3_val*i\n            bleu_3_val+=bleu_3_score(Y_true,Y_pred)\n            bleu_3_val/=(i+1)\n            \n            bleu_4_val=bleu_4_val*i\n            bleu_4_val+=bleu_4_score(Y_true,Y_pred)\n            bleu_4_val/=(i+1)\n                \n            del inputs\n            del targets\n            del outputs\n            torch.cuda.empty_cache()\n            \n            progress_bar.update(i + 1, [('test_loss', val_loss),('test_bleu_1', bleu_1_val),('test_bleu_2', bleu_2_val),\n                                        ('test_bleu_3', bleu_3_val),('test_bleu_4', bleu_4_val)])\n            \n    print(f\"test Loss: {val_loss:.4f}, test_bleu_1: {bleu_1_val:.4f}, test_bleu_2: {bleu_2_val:.4f}, test_bleu_3: {bleu_3_val:.4f}, test_bleu_4: {bleu_4_val:.4f},\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T07:14:40.843046Z","iopub.execute_input":"2024-05-26T07:14:40.843800Z","iopub.status.idle":"2024-05-26T07:14:40.856955Z","shell.execute_reply.started":"2024-05-26T07:14:40.843759Z","shell.execute_reply":"2024-05-26T07:14:40.855852Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\nevaluate(model,criterion,device,Test_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T07:14:41.352770Z","iopub.execute_input":"2024-05-26T07:14:41.353998Z","iopub.status.idle":"2024-05-26T07:24:52.876600Z","shell.execute_reply.started":"2024-05-26T07:14:41.353942Z","shell.execute_reply":"2024-05-26T07:24:52.875449Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 8s/step - test_loss: 0.6867 - test_bleu_1: 0.0408 - test_bleu_2: 0.0179 - test_bleu_3: 0.0130 - test_bleu_4: 0.0113\ntest Loss: 0.6868, test_bleu_1: 0.0410, test_bleu_2: 0.0180, test_bleu_3: 0.0129, test_bleu_4: 0.0112,\n","output_type":"stream"}]},{"cell_type":"code","source":"sentences","metadata":{"execution":{"iopub.status.busy":"2024-05-26T08:49:04.041060Z","iopub.execute_input":"2024-05-26T08:49:04.041736Z","iopub.status.idle":"2024-05-26T08:49:04.062405Z","shell.execute_reply.started":"2024-05-26T08:49:04.041704Z","shell.execute_reply":"2024-05-26T08:49:04.061326Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[['▁ರಷ್ಟು', '▁ರೂ'],\n ['▁ಈ', '▁ಬಗ್ಗೆ', '▁ಸರ್ಕಾರ', 'ೂ', '▁ಯಾವುದೇ', '▁ಯಾವುದೇ', '▁ಎಂದು'],\n ['▁ರಷ್ಟು', '▁ಕೋಟಿ', '▁ರೂ'],\n ['▁ಎಂದು', '▁ಅವರು'],\n ['▁ಇದು', '▁ತುಂಬಾ', '▁ಸುಲಭ'],\n [],\n ['▁ಈ', '▁ಮತ್ತು', '▁ಮತ್ತು', 'ೕ', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ನಾನು', '▁ಏನು'],\n ['▁ಇದು', '▁ಒಂದು'],\n ['▁ಈ',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು'],\n ['▁ಈ',\n  '▁ವೇಳೆ',\n  '▁ಅವರು',\n  '▁ನರೇಂದ್ರ',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು'],\n ['▁ಯೆ', 'ಹೋ', 'ವನ', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ನಾನು', '▁ನಾನು'],\n ['▁ಮಾಜಿ', '▁ಸಚಿವ'],\n ['▁ಈ', '▁ಬಾರಿ'],\n ['▁ಪ್ರಧಾನಿ',\n  '▁ನರೇಂದ್ರ',\n  '▁ಮೋದಿ',\n  '▁ಅವರು',\n  '▁ಗಾಂಧಿ',\n  '▁ಗಾಂಧಿ',\n  '▁ಗಾಂಧಿ',\n  '▁ಗಾಂಧಿ',\n  '▁ಗಾಂಧಿ',\n  '▁ಗಾಂಧಿ',\n  '▁ಗಾಂಧಿ',\n  '▁ಗಾಂಧಿ',\n  '▁ಗಾಂಧಿ'],\n ['▁ನಾನು', '▁ನಾನು'],\n ['▁ಆದರೆ', '▁ಯೆ', 'ಹೋ', 'ವನ', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ಆದರೆ', '▁ಈ', '▁ಬಗ್ಗೆ', '▁ಈ', '▁ಬಗ್ಗೆ', '▁ಎಂದು', '▁ಎಂದು'],\n ['▁ಆದರೆ', '▁ಈ', '▁ಈ'],\n ['▁ಯೆ', 'ಹೋ', 'ವನ', 'ನ್ನು', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ಈ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಆದರೆ', '▁ಈ', '▁ಈ'],\n ['▁ನಿಮ್ಮ', 'ಮಾತ್ರ', 'ವಲ್ಲದೆ', '▁ಮತ್ತು', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ಮತ್ತು'],\n ['▁ರಷ್ಟು'],\n ['▁ಇದು', '▁ಈ', 'ೕ'],\n ['▁ಈ', '▁ಈ', '▁ಒಂದು'],\n ['▁ಈ', '▁ವಿಡಿಯೋ', '▁ಮತ್ತು', 'ೂ'],\n ['▁ಈ', '▁ಬಗ್ಗೆ'],\n ['▁ಈ', '▁ಚಿತ್ರದ', '▁ಸಿನಿಮಾ', '▁ಸಿನಿಮಾ'],\n ['▁ಈ', '▁ವೇಳೆ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಈ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಈ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಇದು', '▁ಪ್ರಶ್ನೆ'],\n ['▁ಈ', 'ಗೆ', 'ೂ', '▁ವೈರಲ್'],\n ['▁ನಾವು', '▁ಯಾವುದೇ'],\n ['▁ಅವರು', '▁ತಮ್ಮ', 'ದ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಬೆಂಗಳೂರು', '▁ಜಿಲ್ಲಾ'],\n ['▁ನಾನು', '▁ನನ್ನ', '▁ದೇವರ', 'ನ್ನು', '▁ಯೆ', 'ಹೋ', 'ವನ', 'ು'],\n ['▁ಮತ್ತು'],\n ['ೕ'],\n ['▁ನಾನು', '▁ನಾನು', '▁ನಾನು'],\n ['▁ಈ'],\n ['▁ರಷ್ಟು'],\n ['▁ಈ', '▁ಖಾನ್', '▁ಖಾನ್', '▁ನಟ', '▁ಖಾನ್', '▁ಖಾನ್', '▁ಅವರ', '▁ಮೇಲೆ'],\n ['▁ಅವರು'],\n ['▁ಏನು', 'ೕ'],\n ['▁ಇದು', '▁ಪ್ರಶ್ನೆ'],\n ['▁ಈ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಈ', '▁ಬಗ್ಗೆ'],\n ['▁ಇದು', '▁ಈ', 'ೕ', 'ೕ'],\n ['▁ಈ',\n  '▁ಗಾಂಧಿ',\n  '▁ಖಾನ್',\n  '▁ಅವರ',\n  '▁ಪುತ್ರ',\n  '▁ಮತ್ತು',\n  '▁ಅವರ',\n  '▁ಪುತ್ರ',\n  '▁ಮತ್ತು',\n  '▁ಗಾಂಧಿ',\n  '▁ಮತ್ತು'],\n ['▁ಮಾಜಿ',\n  '▁ಮುಖ್ಯಮಂತ್ರಿ',\n  '▁ಮಾಜಿ',\n  '▁ಮುಖ್ಯಮಂತ್ರಿ',\n  '▁ಸಿಂಗ್',\n  '▁ಮಾಜಿ',\n  '▁ಮುಖ್ಯಮಂತ್ರಿ',\n  '▁ಸಿಂಗ್',\n  '▁ಮಾಜಿ',\n  '▁ಮುಖ್ಯಮಂತ್ರಿ',\n  '▁ಸಿಂಗ್',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು'],\n ['▁ಈ', '▁ಮೂಲಕ', 'ಗೆ', 'ೂ'],\n ['▁ಯೆ', 'ಹೋ', 'ವನ', '▁ಸಾಕ್ಷಿ', 'ಗಳು', '▁ಮತ್ತು', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ನಿಮ್ಮ', '▁ನಿಮ್ಮ', '▁ನಿಮ್ಮ', '▁ನಿಮ್ಮ'],\n [],\n ['▁ಯೆ', 'ಹೋ', 'ವನ', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ಈ', '▁ವೇಳೆ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಇದು', '▁ಒಂದು'],\n ['▁ಈ', '▁ಈ', '▁ಈ', '▁ಈ'],\n ['▁ಈ', '▁ಬಗ್ಗೆ', '▁ಈ'],\n ['▁ಆದರೆ', '▁ಈ', '▁ಬಗ್ಗೆ', 'ೂ'],\n ['▁ನೀವು', '▁ನಿಮ್ಮ', '▁ನಿಮ್ಮ', '▁ಹೇಗೆ'],\n ['▁ಅವರು', '▁ಯೆ', 'ಹೋ', 'ವನ', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ಈ', '▁ಬಗ್ಗೆ', '▁ಸರ್ಕಾರ'],\n ['▁ಈ', '▁ಆರೋಗ್ಯ', 'ಗಳು'],\n ['▁ಈ', '▁ಮತ್ತು', 'ಗೆ', 'ೂ', 'ಗೆ'],\n ['▁ನಿಮ್ಮ', '▁ಮತ್ತು', 'ೕ', 'ೕ'],\n ['▁ಈ',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು'],\n ['▁ಈ', '▁ಚಿತ್ರದ', '▁ಚಿತ್ರದ', '▁ಸಿನಿಮಾ', '▁ಸಿನಿಮಾ'],\n ['▁ಈ',\n  '▁ಬಗ್ಗೆ',\n  '▁ನರೇಂದ್ರ',\n  '▁ಮೋದಿ',\n  '▁ನರೇಂದ್ರ',\n  '▁ಮೋದಿ',\n  '▁ನರೇಂದ್ರ',\n  '▁ಮೋದಿ',\n  '▁ಮೋದಿ',\n  '▁ಮೋದಿ'],\n ['▁ಈ', '▁ಈ', '▁ಈ', 'ೂ'],\n ['▁ಈ',\n  '▁ಕುಮಾರ್',\n  '▁ಮಾಜಿ',\n  '▁ಮಾಜಿ',\n  '▁ನಾಯಕ',\n  '▁ವಿರಾಟ್',\n  '▁ಕೊಹ್ಲಿ',\n  '▁ಸಿಂಗ್',\n  '▁ಸಿಂಗ್',\n  '▁ಸಿಂಗ್',\n  '▁ಸಿಂಗ್',\n  '▁ಸಿಂಗ್',\n  '▁ಸಿಂಗ್',\n  '▁ಸಿಂಗ್',\n  '▁ಸಿಂಗ್'],\n ['▁ಈ', '▁ಸಂಬಂಧ', 'ದಲ್ಲಿ', '▁ಮತ್ತು', '▁ಕೋಟಿ', '▁ರೂ', '▁ಕೋಟಿ'],\n ['▁ಈ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಆದರೆ', '▁ಈ', '▁ಅವರ', 'ು'],\n [],\n ['▁ಯೆ', 'ಹೋ', 'ವನ', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ಈ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಮತ್ತು'],\n ['▁ಆದರೆ', '▁ಈ', '▁ಬಗ್ಗೆ', 'ೂ'],\n ['▁ಈ', '▁ನಮ್ಮ', 'ಗೆ', 'ೂ', 'ೕ', 'ಗೆ', '▁ಎಂದು'],\n ['▁ವಿರಾಟ್',\n  '▁ಕೊಹ್ಲಿ',\n  '▁ಕೊಹ್ಲಿ',\n  '▁ಕೊಹ್ಲಿ',\n  '▁ಕೊಹ್ಲಿ',\n  '್',\n  '▁ಶರ್ಮಾ',\n  '್',\n  '▁ಧವನ್',\n  '್',\n  '▁ಧವನ್',\n  '್',\n  '್',\n  '್',\n  '್',\n  '್',\n  '್',\n  '್',\n  '್',\n  '್'],\n ['▁ನಾನು', '▁ಯಾರ', 'ಿಗೂ'],\n ['▁ಯೆ', 'ಹೋ', 'ವನು', '▁ಯೆ', 'ಹೋ', 'ವನ', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ಈ', '▁ವಿಡಿಯೋ', 'ವನ್ನು', '▁ವೈರಲ್', '▁ವೈರಲ್'],\n ['▁ಆದರೆ', '▁ಅದು', 'ೂ'],\n ['▁ನಾವು', '▁ಯಾವುದೇ', '▁ನಾವು'],\n ['▁ಈ',\n  '▁ನಮ್ಮ',\n  'ವು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು'],\n ['▁ನಾನು', '▁ಏನು'],\n ['▁ಈ', '▁ಮುಖ್ಯಮಂತ್ರಿ', '▁ಮುಖ್ಯಮಂತ್ರಿ', '▁ಮಾಜಿ', '▁ಮುಖ್ಯಮಂತ್ರಿ', '▁ಯಡಿಯೂರಪ್ಪ'],\n ['▁ಮತ್ತು'],\n ['▁ಸಚಿವ'],\n ['▁ಈ', '▁ವೇಳೆ', '▁ಕುಮಾರ್'],\n ['▁ಅವರು', '▁ನಿಮ್ಮ', 'ನ್ನು', 'ನ್ನು'],\n ['▁ಇದು', '▁ತುಂಬಾ', 'ೂ'],\n ['▁ಆದರೆ', '▁ಅವರು', 'ವನು', '▁ಯೆ', 'ಹೋ', 'ವನ'],\n ['▁ಆದರೆ', '▁ಈ', '▁ಬಗ್ಗೆ'],\n ['▁ಹೊಸ', 'ಗಳು', '▁ಮತ್ತು'],\n ['▁ನಾನು', '▁ಅವರ', 'ನ್ನು'],\n ['▁ಇದು', '▁ಒಂದು'],\n ['▁ಇದು', '▁ನಮ್ಮ', '▁ಕಾರಣಗಳಿಗಾಗಿ', '▁ಮತ್ತು'],\n ['▁ಈ', '▁ಬಗ್ಗೆ'],\n ['▁ಈ',\n  '▁ಸಂದರ್ಭದಲ್ಲಿ',\n  '▁ಭಾರತ',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು'],\n ['▁ಈ', '▁ಬಗ್ಗೆ', '▁ಬಿಜೆಪಿ', '▁ಬಿಜೆಪಿ', '▁ಬಿಜೆಪಿ'],\n ['▁ಇದು', '▁ಅವರ', 'ು', '▁ಮತ್ತು', '▁ಪಾತ್ರ', 'ೂ', 'ೕ'],\n ['▁ನಾನು', '▁ನಾನು', '▁ನಾನು'],\n ['▁ಇದು', '▁ಈ', 'ೕ', 'ೕ'],\n ['▁ಈ', '▁ವೇಳೆ', '▁ಅವರು', '▁ಎಂದು'],\n ['▁ಶಾಲಾ',\n  '▁ಕಾಲೇಜುಗಳು',\n  '▁ಮತ್ತು',\n  '▁ಕಾಶ್ಮೀರದ',\n  '▁ಪ್ರದೇಶಗಳಲ್ಲಿ',\n  '▁ಮತ್ತು',\n  'ಗಳನ್ನು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು'],\n ['▁ನಾನು', '▁ನಾನು', '▁ನಾನು', '▁ನಾನು', '▁ಎಂದು', '▁ಎಂದು'],\n ['▁ನಾನು', '▁ನಾನು'],\n ['▁ಏನು', 'ೕ'],\n ['▁ಇದು', '▁ಒಂದು'],\n ['▁ಈ', '▁ತೆಲುಗು', '▁ಮಲಯಾಳಂ', '▁ಮತ್ತು'],\n ['▁ಈ', '▁ಬಗ್ಗೆ'],\n ['▁ಆದರೆ', '▁ಅವನು', '▁ತನ್ನ', 'ು', 'ದ'],\n ['▁ಅವರು', '▁ನಿಮ್ಮ', 'ೕ'],\n ['▁ಈ', '▁ಚಿತ್ರದಲ್ಲಿ', '▁ನಟಿ', '▁ಮತ್ತು', '▁ಮತ್ತು', '▁ಹಾಗೂ', '▁ಅವರ', '▁ಮೇಲೆ'],\n ['▁ಈ',\n  '▁ಇಂಡೀಸ್',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು',\n  '▁ಮತ್ತು'],\n [],\n [],\n ['▁ಏನು', 'ೕ', 'ೕ'],\n ['▁ನಾನು',\n  '▁ನನ್ನ',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು',\n  'ನು'],\n ['▁ಆದರೆ', '▁ಇದು', '▁ತುಂಬಾ'],\n ['▁ಇದು', '▁ಒಂದು', '▁ಒಂದು'],\n ['▁ಈ', '▁ಈ', '▁ಒಂದು']]"},"metadata":{}}]},{"cell_type":"code","source":"def get_final_sent(sent):\n    final = \"\".join(sent)\n    cleaned_text = final.replace('▁', ' ')\n    return cleaned_text.strip()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:07:27.156366Z","iopub.execute_input":"2024-05-26T13:07:27.156747Z","iopub.status.idle":"2024-05-26T13:07:27.161950Z","shell.execute_reply.started":"2024-05-26T13:07:27.156716Z","shell.execute_reply":"2024-05-26T13:07:27.161034Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Output with teacher forcing\n\n<p style=\"font-size:18px\">\n    Many of these translations make no sense, some are partially making sense, and some are incomplete, it undoubtedly indictes model needs more epoch to train, but due to limited resource we could not make better than this. \n</p>","metadata":{}},{"cell_type":"code","source":"sentences=[]\nfor x,y in tqdm(Test_data):\n    Y_pred= torch.argmax(model(x.T,y.T),axis=-1).T.detach()\n    sentences.extend(id_to_word(Y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:12:41.950339Z","iopub.execute_input":"2024-05-26T09:12:41.951264Z","iopub.status.idle":"2024-05-26T09:16:59.793629Z","shell.execute_reply.started":"2024-05-26T09:12:41.951213Z","shell.execute_reply":"2024-05-26T09:16:59.792725Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"100%|██████████| 79/79 [04:17<00:00,  3.26s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inference\n","metadata":{}},{"cell_type":"code","source":"idx=380\nprint(\"the source sentence: \",Data_test['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_test['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:17:10.520795Z","iopub.execute_input":"2024-05-26T09:17:10.521611Z","iopub.status.idle":"2024-05-26T09:17:10.526887Z","shell.execute_reply.started":"2024-05-26T09:17:10.521581Z","shell.execute_reply":"2024-05-26T09:17:10.525997Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"the source sentence:  here  cases were registered\nthe predicted sentence:  ಈ ಸಂಬಂಧ ಪೊಲೀಸರು\nthe actual sentence:  ಪ್ರಕರಣಗಳು ಬಾಕಿ ಇವೆ ಎಂದು ಮಾಹಿತಿ ನೀಡಿದರು\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=60\nprint(\"the source sentence: \",Data_test['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_test['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:17:12.342408Z","iopub.execute_input":"2024-05-26T09:17:12.343120Z","iopub.status.idle":"2024-05-26T09:17:12.348533Z","shell.execute_reply.started":"2024-05-26T09:17:12.343091Z","shell.execute_reply":"2024-05-26T09:17:12.347637Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"the source sentence:  it is called homa\nthe predicted sentence:  ಇದು ಒಂದು\nthe actual sentence:  ಅದಕ್ಕೆ ಭಸ್ಮಶಯ್ಯೆ ಎಂದು ಹೆಸರು\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=230\nprint(\"the source sentence: \",Data_test['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_test['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:17:14.773382Z","iopub.execute_input":"2024-05-26T09:17:14.773749Z","iopub.status.idle":"2024-05-26T09:17:14.779573Z","shell.execute_reply.started":"2024-05-26T09:17:14.773719Z","shell.execute_reply":"2024-05-26T09:17:14.778560Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"the source sentence:  nothing was heard\nthe predicted sentence:  ನಾನು ಸುಮ್ಮನೆ\nthe actual sentence:  ಯಾವ ಸದ್ದೂ ಕೇಳಲಿಲ್ಲ\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=990\nprint(\"the source senetence: \",Data_test['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_test['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:17:16.418354Z","iopub.execute_input":"2024-05-26T09:17:16.419193Z","iopub.status.idle":"2024-05-26T09:17:16.424913Z","shell.execute_reply.started":"2024-05-26T09:17:16.419166Z","shell.execute_reply":"2024-05-26T09:17:16.423945Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"the source senetence:  what is a parliamentary committee\nthe predicted sentence:  ಬಿಜೆಪಿ ಕಾಂಗ್ರೆಸ್\nthe actual sentence:  ಸಮನ್ವಯ ಸಮಿತಿ ಅಂದರೆ ಏನು\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Output without teacher forcing","metadata":{}},{"cell_type":"code","source":"sentences=[]\nfor x,y in tqdm(Test_data):\n    Y_pred= torch.argmax(model(x.T),axis=-1).T.detach()\n    sentences.extend(id_to_word(Y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:17:27.679132Z","iopub.execute_input":"2024-05-26T09:17:27.680038Z","iopub.status.idle":"2024-05-26T09:22:45.036920Z","shell.execute_reply.started":"2024-05-26T09:17:27.680002Z","shell.execute_reply":"2024-05-26T09:22:45.035916Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"100%|██████████| 79/79 [05:17<00:00,  4.02s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=380\nprint(\"the source sentence: \",Data_test['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_test['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:23:09.338819Z","iopub.execute_input":"2024-05-26T09:23:09.339550Z","iopub.status.idle":"2024-05-26T09:23:09.344967Z","shell.execute_reply.started":"2024-05-26T09:23:09.339520Z","shell.execute_reply":"2024-05-26T09:23:09.344055Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"the source sentence:  here  cases were registered\nthe predicted sentence:  ಈ ಸಂಬಂಧ ಪೊಲೀಸರು\nthe actual sentence:  ಪ್ರಕರಣಗಳು ಬಾಕಿ ಇವೆ ಎಂದು ಮಾಹಿತಿ ನೀಡಿದರು\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=60\nprint(\"the source sentence: \",Data_test['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_test['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:23:11.167315Z","iopub.execute_input":"2024-05-26T09:23:11.167713Z","iopub.status.idle":"2024-05-26T09:23:11.173825Z","shell.execute_reply.started":"2024-05-26T09:23:11.167683Z","shell.execute_reply":"2024-05-26T09:23:11.172891Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"the source sentence:  it is called homa\nthe predicted sentence:  ಇದು ಒಂದು\nthe actual sentence:  ಅದಕ್ಕೆ ಭಸ್ಮಶಯ್ಯೆ ಎಂದು ಹೆಸರು\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=230\nprint(\"the source sentence: \",Data_test['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_test['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:23:13.396175Z","iopub.execute_input":"2024-05-26T09:23:13.396562Z","iopub.status.idle":"2024-05-26T09:23:13.402244Z","shell.execute_reply.started":"2024-05-26T09:23:13.396533Z","shell.execute_reply":"2024-05-26T09:23:13.401278Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"the source sentence:  nothing was heard\nthe predicted sentence:  ನಾನು ಸುಮ್ಮನೆ\nthe actual sentence:  ಯಾವ ಸದ್ದೂ ಕೇಳಲಿಲ್ಲ\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=990\nprint(\"the source sentence: \",Data_test['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_test['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:23:15.461501Z","iopub.execute_input":"2024-05-26T09:23:15.462468Z","iopub.status.idle":"2024-05-26T09:23:15.467678Z","shell.execute_reply.started":"2024-05-26T09:23:15.462435Z","shell.execute_reply":"2024-05-26T09:23:15.466723Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"the source sentence:  what is a parliamentary committee\nthe predicted sentence:  ಬಿಜೆಪಿ ಅಭ್ಯರ್ಥಿ\nthe actual sentence:  ಸಮನ್ವಯ ಸಮಿತಿ ಅಂದರೆ ಏನು\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Result from train data","metadata":{}},{"cell_type":"markdown","source":"# with teacher forcing","metadata":{}},{"cell_type":"code","source":"x,y = next(iter(Train_data))\nY_pred= torch.argmax(model(x.T,y.T),axis=-1).T.detach()\nsentences = id_to_word(Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:07:13.083309Z","iopub.execute_input":"2024-05-26T13:07:13.084055Z","iopub.status.idle":"2024-05-26T13:07:16.988721Z","shell.execute_reply.started":"2024-05-26T13:07:13.084020Z","shell.execute_reply":"2024-05-26T13:07:16.987891Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"idx=0\nprint(\"the source sentence: \",Data_train['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_train['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:07:29.587453Z","iopub.execute_input":"2024-05-26T13:07:29.588229Z","iopub.status.idle":"2024-05-26T13:07:29.593652Z","shell.execute_reply.started":"2024-05-26T13:07:29.588197Z","shell.execute_reply":"2024-05-26T13:07:29.592729Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"the source sentence:  the role of parents\nthe predicted sentence:  ಅವರುುು\nthe actual sentence:  ಆಗಿನ ಪೋಷಕರ ಪಾತ್ರವೂ\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=80\nprint(\"the source sentence: \",Data_train['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_train['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:07:56.930949Z","iopub.execute_input":"2024-05-26T13:07:56.931592Z","iopub.status.idle":"2024-05-26T13:07:56.937420Z","shell.execute_reply.started":"2024-05-26T13:07:56.931560Z","shell.execute_reply":"2024-05-26T13:07:56.936458Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"the source sentence:  there are numerous complaints regarding this issue\nthe predicted sentence:  ಈ ಬಗ್ಗೆ ಈ ಕ್ರಮ ಎಂದು\nthe actual sentence:  ಈ ಬಗ್ಗೆ ಸಾಕಷ್ಟು ದೂರುಗಳೂ ಬರುತ್ತಿವೆ\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=127\nprint(\"the source sentence: \",Data_train['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_train['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:08:28.245050Z","iopub.execute_input":"2024-05-26T13:08:28.245415Z","iopub.status.idle":"2024-05-26T13:08:28.251422Z","shell.execute_reply.started":"2024-05-26T13:08:28.245385Z","shell.execute_reply":"2024-05-26T13:08:28.250454Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"the source sentence:  the existing mlas will contest elections on  seats\nthe predicted sentence:  ಈ ಚುನಾವಣೆ ಮತ್ತು ಬಿಜೆಪಿ ಬಿಜೆಪಿ\nthe actual sentence:  ಹಾಲಿ ಶಾಸಕರು ಸ್ಥಾನಗಳಲ್ಲಿ ಸ್ಪರ್ಧಿಸಲಿದ್ದಾರೆ\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## without teacher forcing","metadata":{}},{"cell_type":"code","source":"Y_pred= torch.argmax(model(x.T),axis=-1).T.detach()\nsentences = id_to_word(Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:09:21.759952Z","iopub.execute_input":"2024-05-26T13:09:21.760903Z","iopub.status.idle":"2024-05-26T13:09:26.552545Z","shell.execute_reply.started":"2024-05-26T13:09:21.760866Z","shell.execute_reply":"2024-05-26T13:09:26.551765Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"idx=0\nprint(\"the source sentence: \",Data_train['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_train['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:09:30.352854Z","iopub.execute_input":"2024-05-26T13:09:30.353205Z","iopub.status.idle":"2024-05-26T13:09:30.359195Z","shell.execute_reply.started":"2024-05-26T13:09:30.353178Z","shell.execute_reply":"2024-05-26T13:09:30.358236Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"the source sentence:  the role of parents\nthe predicted sentence:  ಅವರು\nthe actual sentence:  ಆಗಿನ ಪೋಷಕರ ಪಾತ್ರವೂ\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=80\nprint(\"the source sentence: \",Data_train['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_train['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:09:37.329591Z","iopub.execute_input":"2024-05-26T13:09:37.330075Z","iopub.status.idle":"2024-05-26T13:09:37.335714Z","shell.execute_reply.started":"2024-05-26T13:09:37.330042Z","shell.execute_reply":"2024-05-26T13:09:37.334796Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"the source sentence:  there are numerous complaints regarding this issue\nthe predicted sentence:  ಈ ಬಗ್ಗೆ ಈ ಕ್ರಮ\nthe actual sentence:  ಈ ಬಗ್ಗೆ ಸಾಕಷ್ಟು ದೂರುಗಳೂ ಬರುತ್ತಿವೆ\n","output_type":"stream"}]},{"cell_type":"code","source":"idx=127\nprint(\"the source sentence: \",Data_train['source'][idx])\nprint(\"the predicted sentence: \",get_final_sent(sentences[idx]))\nprint(\"the actual sentence: \",Data_train['target'][idx])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:09:46.616316Z","iopub.execute_input":"2024-05-26T13:09:46.617030Z","iopub.status.idle":"2024-05-26T13:09:46.622432Z","shell.execute_reply.started":"2024-05-26T13:09:46.616998Z","shell.execute_reply":"2024-05-26T13:09:46.621432Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"the source sentence:  the existing mlas will contest elections on  seats\nthe predicted sentence:  ಈ ಸಂಬಂಧ ವಿಧಾನಸಭಾ ಚುನಾವಣೆಗೆ ಚುನಾವಣೆ\nthe actual sentence:  ಹಾಲಿ ಶಾಸಕರು ಸ್ಥಾನಗಳಲ್ಲಿ ಸ್ಪರ್ಧಿಸಲಿದ್ದಾರೆ\n","output_type":"stream"}]}]}